# Random Forest

### Sample code to run the program 
for serial: go run randomforest/tree.go s 200 4
for stealing: go run randomforest/tree.go stl 200 4 8 10
for balancing: go run randomforest/tree.go bal 200 4 8 10 2

### Observations

The code is speeding up well on increasing the number of threads. The speed up is almost linear to start with and it starts decreasing after a point as the overhead cost starts increasing. What the code does and what part has been parallelised has been answered in the next segment.  
The graph generated by the code is given below:  

![Speedup Curves](speedup.png)

### Describe in detailed of your system and the problem it is trying to solve

The code implements a machine learning method - Random Forest, to solve a classification problem.  
It assumes that the data given has n-1 X variables and the last column is the y variable. Then, the code splits the given data into train and test, with 30% data reserved for testing. Post this, the data is sent to the algorithm for classification. The algorithm randomly takes sqrt(n) columns (also called features) and runs the decision tree algorithm on it. This is done repeatedly for around 200 trees and then for any random data (test data in our case), each tree predicts what should be the class for a given line item and the class which has the highest votes is declared as the class for the given dataset. This is also called the wisdon of the crowds.  
For our case, a task is training a decision tree, since each tree can be trained independent of the others, the task is easily parallelisable. 

### A description of how you implemented your parallel solutions

The stealing algorithm keeps taking items from the global queue till either the threshold is crossed or there are no more items in the global queue. If at that time, there are more than 0 elements in the queue, the thread does work on the tasks it has in the queue. However, if the thread checks in the global queue and there are no elements in it, it tries to steal work from one of the other threads and if it is successful, it does work and the process is repeated.  
The distribution algorithm keeps taking items from the global queue till either the threshold is crossed or there are no more items in the global queue. If at that time, there are more than 0 elements in the queue, the thread does work on the tasks it has in the queue. After each task, the thread generates a random number between the number 1 and the number of elements in the queue and if that is equal to the number of items in the queue, then work distribution happens. Here, a thread is selected at random and if the absoluted difference between the number of elements in the thread selected and this thread is greater than a threshold value, the tasks are distributed till both have same number of tasks.

### Describe the challenges you faced while implementing the system. What aspects of the system might make it difficult to parallelize? In other words, what to you hope to learn by doing this assignment?

The main challenge while implementing the systems was to get a good hang of how futures work and how interfaces are typecasted for callables and runnables. This was the major challenge while doing this assignment, and learning this helped in getting a better understanding of how some values can be returned despite them not being calculated at the moment. 

### Specifications of the testing machine you ran your experiments on (i.e. Core Architecture (Intel/AMD), Number of cores, operating system, memory amount, etc.)

I tested the code on linux6 terminal. Below are the details of the same:  

CPU op-mode(s):                  32-bit, 64-bit  
CPU(s):                          64  
On-line CPU(s) list:             0-63  
Thread(s) per core:              2  
Core(s) per socket:              16  
Socket(s):                       2  
Model name:                      Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz  

### What are the hotspots (i.e., places where you can parallelize the algorithm) and bottlenecks (i.e., places where there is sequential code that cannot be parallelized) in your sequential program? Were you able to parallelize the hotspots and/or remove the bottlenecks in the parallel version?

The hotspots are making the trees which I was able to parallelise.  
The bottleneck is the preprocessing of the data and finally convergin result from all the trees which cant be parallelised because of the data dependencies involved.

### What limited your speedup? Is it a lack of parallelism? (dependencies) Communication or synchronization overhead? As you try and answer these questions, we strongly prefer that you provide data and measurements to support your conclusions.

I am almost getting a linear speed up and after a certain point, because of the overhead associated with the threads, the speed up is reducing slightly, but still the speed up is pretty good

### Compare and contrast the two parallel implementations. Are there differences in their speedups?

The stealing algorithm slightly outperforms the balancing algorithm. The reason being, there are some overheads associated with the balancing algorithm where in we have to keep generating the random numbers after every work and see if work has to be distributed. Because of this, the speed up, although good for balancing, is not as good as for stealing. 